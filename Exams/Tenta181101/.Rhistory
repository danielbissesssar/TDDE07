x_matrix[2,1] = rgamma(1, 1, 1)
x_matrix[3,1] = rgamma(1, 1, 1)
x_matrix[100,1] = rgamma(1, 1, 1)
x_matrix[101,1] = rgamma(1, 1, 1)
x_matrix
count = 0
count = 0
for(grid in 1:length(grid)){
count = count + 1
x_matrix[count,1] = rgamma(i, 1, 1)
#x_matrix[i,2] = rgamma(i, 1, 1)
# x_matrix[i,2] = rgamma(i, 1, 1)
}
count
count = 0
for(grid in 1:length(grid)){
count = count + 1
x_matrix[count,1] = rgamma(1, 1, 1)
#x_matrix[i,2] = rgamma(i, 1, 1)
# x_matrix[i,2] = rgamma(i, 1, 1)
}
x_matrix
# 4b
# Setting up data and prior
y <- c(184,67,149)
alpha <- c(1,1,1) # Dirichlet prior hyperparameters
nIter <- 10000 # Number of posterior draws
# Defining a function that simulates from a Dirichlet distribution
SimDirichlet <- function(nIter, param){
nCat <- length(param)
thetaDraws <- as.data.frame(matrix(NA, nIter, nCat)) # Storage.
for (j in 1:nCat){
thetaDraws[,j] <- rgamma(nIter,param[j],1)
}
for (i in 1:nIter){
thetaDraws[i,] = thetaDraws[i,]/sum(thetaDraws[i,])
}
return(thetaDraws)
}
#get theta draws from its posterior distribution
theta_draws = SimDirichlet(nIter, alpha + y)
theta_draws
theta_draws
sum(theta_draws[,1]>0.5)
sum(theta_draws[,1]>0.5)/nIter
sum(theta_draws[,1] > theta_draws[,2] & theta_draws[,1]> theta_draws[,3])
sum(theta_draws[,1] > theta_draws[,2] & theta_draws[,1]> theta_draws[,3])
sum(theta_draws[,1] > theta_draws[,2] & theta_draws[,1]> theta_draws[,3])/nIter
mean(theta_draws[,1])
setwd("C:/Users/Arun/Bayesian_Learning_TDDE07/Tenta181101")
# Bayesian Learning Exam 2018-11-01
# Run this file once during the exam to get all the required data and functions for the exam in working memory
# Author: Per Siden
###############################
########## Problem 1 ##########
###############################
###############################
########## Problem 2 ##########
###############################
# Reading the data from file
load(file = 'fish.RData')
install.packages("mvtnorm")
library(mvtnorm)
# Defining a function that simulates from the scaled inverse Chi-square distribution
rScaledInvChi2 <- function(n, df, scale){
return((df*scale)/rchisq(n,df=df))
}
BayesLinReg <- function(y, X, mu_0, Omega_0, v_0, sigma2_0, nIter){
# Direct sampling from a Gaussian linear regression with conjugate prior:
#
# beta | sigma2 ~ N(mu_0, sigma2*inv(Omega_0))
# sigma2 ~ Inv-Chi2(v_0,sigma2_0)
#
# Author: Mattias Villani, IDA, Linkoping University. http://mattiasvillani.com
#
# INPUTS:
#   y - n-by-1 vector with response data observations
#   X - n-by-nCovs matrix with covariates, first column should be ones if you want an intercept.
#   mu_0 - prior mean for beta
#   Omega_0  - prior precision matrix for beta
#   v_0      - degrees of freedom in the prior for sigma2
#   sigma2_0 - location ("best guess") in the prior for sigma2
#   nIter - Number of samples from the posterior (iterations)
#
# OUTPUTS:
#   results$betaSample     - Posterior sample of beta.     nIter-by-nCovs matrix
#   results$sigma2Sample   - Posterior sample of sigma2.   nIter-by-1 vector
# Compute posterior hyperparameters
n = length(y) # Number of observations
nCovs = dim(X)[2] # Number of covariates
XX = t(X)%*%X
betaHat <- solve(XX,t(X)%*%y)
Omega_n = XX + Omega_0
mu_n = solve(Omega_n,XX%*%betaHat+Omega_0%*%mu_0)
v_n = v_0 + n
sigma2_n = as.numeric((v_0*sigma2_0 + ( t(y)%*%y + t(mu_0)%*%Omega_0%*%mu_0 - t(mu_n)%*%Omega_n%*%mu_n))/v_n)
invOmega_n = solve(Omega_n)
# The actual sampling
sigma2Sample = rep(NA, nIter)
betaSample = matrix(NA, nIter, nCovs)
for (i in 1:nIter){
# Simulate from p(sigma2 | y, X)
sigma2 = rScaledInvChi2(n=1, df = v_n, scale = sigma2_n)
sigma2Sample[i] = sigma2
# Simulate from p(beta | sigma2, y, X)
beta_ = rmvnorm(n=1, mean = mu_n, sigma = sigma2*invOmega_n)
betaSample[i,] = beta_
}
return(results = list(sigma2Sample = sigma2Sample, betaSample=betaSample))
}
###############################
########## Problem 3 ##########
###############################
# No code or data for this problem
###############################
########## Problem 4 ##########
###############################
# Reading the data from file
load(file = 'weibull.RData')
install.packages("mvtnorm")
y = c(1690, 1790, 1760, 1750)
sigma^2 = 50^2
y = c(1690, 1790, 1760, 1750)
sigma2 = 50^2
y = c(1690, 1790, 1760, 1750)
sigma2 = 50^2
length(y)
sumY = sum(y)
sumY
#Make draws from posterior
theta_draws = rnorm(1000, mean = sumY, sd = sqrt(sigma2/n))
#Make draws from posterior using non informative prior
theta_draws = rnorm(1000, mean = sumY, sd = sqrt(sigma2/n))
thetaGrid = seq(0,100, length = 1000)
plot(thetaGrid, dnorm(1000, mean = theta_draws, sd = sqrt(sigma2)))
#Make draws from posterior using non informative prior
theta_draws = rnorm(1000, mean = sumY, sd = sqrt(sigma2/n))
theta_draws
plot(thetaGrid, dnorm(thetaGrid, mean = theta_draws, sd = sqrt(sigma2)))
plot(rnorm(1000, mean = theta_draws, sd = sqrt(sigma2)))
myDraws = rnorm(1000, mean = theta_draws, sd = sqrt(sigma2))
hist(myDraws)
par(mfrow = c(1,1))
myDraws = rnorm(1000, mean = theta_draws, sd = sqrt(sigma2))
hist(myDraws)
#What is the prob that a weight in the next 365 days will have be larger than 230
max_weight = c()
for (i in 1:nSim){
prediction_52_weeks = max(rnorm(52, mean = theta_draws, sd = sqrt(sigma2)))
max_weight = append(max_weight, prediction_365_days)
}
#What is the prob that a weight in the next 365 days will have be larger than 230
max_weight = c()
for (i in 1:nSim){
prediction_52_weeks = max(rnorm(52, mean = theta_draws, sd = sqrt(sigma2)))
max_weight = append(max_weight, prediction_52_weeks)
}
max_weight
rnorm(52, mean = theta_draws, sd = sqrt(sigma2))
hist(myDraws, freq = FALSE)
hist(myDraws, freq = FALSE, 40)
myDraws
meanY = mean(y)
#Make draws from posterior using non informative prior
theta_draws = rnorm(1000, mean = meanY, sd = sqrt(sigma2/n))
thetaGrid = seq(0,100, length = 1000)
par(mfrow = c(1,1))
myDraws = rnorm(1000, mean = theta_draws, sd = sqrt(sigma2))
hist(myDraws, freq = FALSE, 40)
#What is the prob that a weight in the next 365 days will have be larger than 230
max_weight = c()
for (i in 1:1000){
prediction_52_weeks = max(rnorm(52, mean = theta_draws, sd = sqrt(sigma2)))
max_weight = append(max_weight, prediction_52_weeks)
}
max_weight
mean(max_weight>1850)/1000
sum(max_weight>1850)
#What is the prob that a weight in the next 365 days will have be larger than 230
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, prediction_52_weeks)
}
cases_larger
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2))
prediction_52_weeks
sum(prediction_52_weeks > 1850)
#What is the prob that a weight in the next 365 days will have be larger than 230
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
cases_larger
mean(cases_larger)
aGrid = seq(0,1000)
aGrid
cases_larger
ExpectedLoss<-function(a){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2))
#probCollapse = sum(prediction_52_weeks>100*log(a))/1000
#ProbCollapse = sum(maxWeightYear>10*a)/nSim
EL = a + sum(prediction_52_weeks>100*log(a))
return(EL)
}
p = ExpectedLoss(2)
ExpectedLoss(2)
ExpectedLoss(5)
ExpectedLoss(20)
sum(prediction_52_weeks>100*log(a))
sum(prediction_52_weeks>100*log(2))
sum(prediction_52_weeks>100*log(5))
sum(prediction_52_weeks>100*log(100))
100*log(34)
100*log(2)
sum(prediction_52_weeks>100*log(100))
sum(prediction_52_weeks>100*log(1000))
sum(prediction_52_weeks>100*log(10000))
prediction_52_weeks
100*log(200)
100*log(2000)
100*log(20000)
100*log(200000)
100*log(200000)
100*log(2000000)
1090*log(2000000)
1090*log(2000)
1000*log(2000)
1000*log(200)
1000*log(20)
aGrid = seq(0,20)
loss = c()
for(a in aGrid){
loss = append(loss, ExpectedLoss(a))
}
loss
sum(prediction_52_weeks>1000*log(2))
sum(prediction_52_weeks>1000*log(20))
sum(prediction_52_weeks>1000*log(10))
sum(prediction_52_weeks>1000*log(1))
sum(prediction_52_weeks>1000*log(2))
sum(prediction_52_weeks>1000*log(3))
sum(prediction_52_weeks>1000*log(4))
sum(prediction_52_weeks>1000*log(9))
sum(prediction_52_weeks>1000*log(8))
sum(prediction_52_weeks>1000*log(10))
sum(prediction_52_weeks>1000*log(7))
sum(prediction_52_weeks>1000*log(6))
aGrid = seq(0,20, length = 1000)
ExpectedLoss<-function(a){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2))
#probCollapse = sum(prediction_52_weeks>100*log(a))/1000
#ProbCollapse = sum(maxWeightYear>10*a)/nSim
EL = a + sum(prediction_52_weeks>1000*log(a))
return(EL)
}
loss = c()
for(a in aGrid){
loss = append(loss, ExpectedLoss(a))
}
loss
plot(aGrid, loss)
aMode = which.min(loss)
aMode
aMode = aGrid[which.min(loss)]
aMode
abline(h = aMmode)
aMode = aGrid[which.min(loss)]
aMode
abline(h = aMmode)
aMode = aGrid[which.min(loss)]
plot(aGrid, loss)
abline(h = aMode)
abline(h = aMode, col = "green")
plot(aGrid, loss, type = 'l')
aMode = aGrid[which.min(loss)]
abline(h = aMode, col = "green")
#Make draws from posterior using non informative prior
yDraws = rnorm(1000, mean = meanY, sd = sqrt(sigma2 + sigma2/n))
plot(yDraws)
#Make draws from posterior using non informative prior
yDraws = rnorm(1000, mean = meanY, sd = sqrt(sigma2 + sigma2/n))
hist(yDraws)
hist(yDraws, freq = FALSE)
hist(yDraws, freq = FALSE, 50)
sum(yDraws>1850)
yDraws
sum(yDraws>1850)/1000
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
#What is the prob that a weight in the next 365 days will have be larger than 230
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
cases_larger
mean(cases_larger)
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
sum(prediction_52_weeks > 1850)
sum(prediction_52_weeks > 1850)
prediction_52_weeks
prediction_52_weeks
prediction_52_weeks
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
draws_larger_than
cases_larger
#What is the prob that a weight in the next 365 days will have be larger than 230
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = theta_draws, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
#What is the prob that a weight in the next 365 days will have be larger than 230
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
cases_larger
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
nSim = 1000
y = c(1690,1790,1760,1750)
n = length(y)
sigma2 = 50^2
maxWeightGivenDay = rnorm(nSim, mean = mean(y), sd = sqrt(sigma2/n+sigma2))
par(mfrow=c(1,1))
hist(maxWeightGivenDay,50)
# 1b)
weekWeightYear = matrix(NA,52,nSim)
for (i in 1:nSim){
weekWeightYear[,i] = t(rnorm(52, mean = mean(y), sd = sqrt(sigma2/n+sigma2)))
}
countWeightYear = colSums(weekWeightYear > 1850)
hist(countWeightYear,50)
sum(countWeightYear)/nSim
cases_larger = c()
for (i in 1:1000){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2/n))
draws_larger_than = sum(prediction_52_weeks > 1850)
cases_larger = append(cases_larger, draws_larger_than)
}
mean(cases_larger)
aGrid = seq(0,20, length = 1000)
ExpectedLoss<-function(a){
prediction_52_weeks = rnorm(52, mean = meanY, sd = sqrt(sigma2 + sigma2/n))
#probCollapse = sum(prediction_52_weeks>100*log(a))/1000
#ProbCollapse = sum(maxWeightYear>10*a)/nSim
EL = a + sum(prediction_52_weeks>1000*log(a))
return(EL)
}
loss = c()
for(a in aGrid){
loss = append(loss, ExpectedLoss(a))
}
plot(aGrid, loss, type = 'l')
aMode = aGrid[which.min(loss)]
abline(h = aMode, col = "green")
aMode
# 1c)
ExpectedLoss<-function(a, weekWeightYear){
EL = a + mean(colSums(weekWeightYear>1000*log(a)))
return(EL)
}
aGrid = seq(2,10,by = 0.01)
EL = rep(NA,length(aGrid),1)
count = 0
for (a in aGrid){
count = count + 1
EL[count] = ExpectedLoss(a, weekWeightYear)
}
plot(aGrid, EL, type = "l")
aOpt = aGrid[which.min(EL)] # This is the optimal a
points(x= aOpt, y = ExpectedLoss(a=aOpt, weekWeightYear), col = "red")
aOpt
# Roughly 6.74
